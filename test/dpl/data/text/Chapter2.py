#!/usr/bin/env python
# coding: utf-8

# # 2 科学計算、データ加工、グラフ描画ライブラリの使い方の基礎

# データサイエンスではさまざまな処理が必要になりますが、そのプログラムをすべて1から作っていては作業効率が落ちてしまいます。そこで基本的なデータ分析には、Pythonのライブラリを使います。2章では、Numpy、Scipy、Pandas、Matplotlibというデータ分析でよく使う4つのライブラリについて、基本的な使い方を紹介していきます。この後の章でも使用するライブラリなので、ここでしっかりと基礎を押さえておきましょう。
# 
# ゴール：Numpy、Scipy、Pandas、Matplotlibのライブラリを読み込み、それらの基本的な役割を知り、使い方がわかる

# - **[2.1-データ分析で使うライブラリ](#2.1-データ分析で使うライブラリ)** 
#     - [2.1.1-ライブラリの読み込み](#2.1.1-ライブラリの読み込み)
#     - [2.1.2-マジックコマンド](#2.1.2-マジックコマンド)
#     - [2.1.3-この章で使うライブラリのインポート](#2.1.3-この章で使うライブラリのインポート)
# <br><br>
# - **[2.2-Numpyの基礎](#2.2-Numpyの基礎)** 
#     - [2.2.1-Numpyのインポート](#2.2.1-Numpyのインポート)
#     - [2.2.2-配列操作](#2.2.2-配列操作)
#     - [2.2.3-乱数](#2.2.3-乱数)
#     - [2.2.4-行列](#2.2.4-行列)
# <br><br>
# - **[2.3 Scipyの基礎](#2.3-Scipyの基礎)** 
#     - [2.3.1 Scipyのライブラリのインポート](#2.3.1-Scipyのライブラリのインポート)
#     - [2.3.2 行列計算](#2.3.2-行列計算)
#     - [2.3.3 ニュートン法](#2.3.3-ニュートン法)
# <br><br>
# - **[2.4-Pandasの基礎](#2.4-Pandasの基礎)** 
#     - [2.4.1 Pandasのライブラリのインポート](#2.4.1-Pandasのライブラリのインポート)
#     - [2.4.2 Seriesの使い方](#2.4.2-Seriesの使い方)
#     - [2.4.3 DataFrameの使い方](#2.4.3-DataFrameの使い方)
#     - [2.4.4 行列操作](#2.4.4-行列操作)
#     - [2.4.5 データの抽出](#2.4.5-データの抽出)
#     - [2.4.6 データの削除と結合](#2.4.6-データの削除と結合)
#     - [2.4.7 集計](#2.4.7-集計)
#     - [2.4.8 値のソート](#2.4.8-値のソート)
#     - [2.4.9 nan（null）の判定](#2.4.9-nan（null）の判定)
# <br><br>
# - **[2.5 Matplotlibの基礎](#2.5-Matplotlibの基礎)**
#     - [2.5.1 Matplotlabを使うための準備](#2.5.1-Matplotlabを使うための準備)
#     - [2.5.2 散布図](#2.5.2-散布図)
#     - [2.5.3 グラフの分割](#2.5.3-グラフの分割)
#     - [2.5.4 関数グラフの描画](#2.5.4-関数グラフの描画)
#     - [2.5.5 ヒストグラム](#2.5.5-ヒストグラム)
# <br><br>
# - **[2.6-総合問題](#2.6-総合問題)**
#     - [■総合問題2-1-モンテカルロ法](#■総合問題2-1-モンテカルロ法)

# 
# ***

# ## 2.1 データ分析で使うライブラリ
# キーワード：ライブラリ、インポート、マジックコマンド、Numpy、Scipy、Pandas、Matplotlib
# 
# データサイエンスでは、大量のデータを加工して分析したり、科学計算したりします。そうした計算処理をするためのプログラムを都度、作っていては作業効率が落ちてしまいます。そこで基本的なデータ分析には、Pythonのライブラリを使います。
# ライブラリとは、自分のプログラムに組み込んで使えるように考慮された外部のプログラムのことです。ライブラリを読み込むことで、自分でいちから処理を書かなくても、複雑な計算ができるようになります。
# 
# さまざまなライブラリがありますが、データサイエンスでよく使われるライブラリは、次の4つです。この章では、これらの4つのライブラリの基本的な使い方を見ていきます。詳しい使い方は後の章で学ぶことにします。
# 
# - Numpy（ナンパイ）：基本的な配列処理や数値計算をするライブラリ。高度で複雑な計算ができるほか、Pythonの通常の計算に比べて処理速度が速い。さまざまなところで使われており、データ分析で使うのに基本中の基本とも言えるライブラリ
# - Scipy（サイパイ）：Numpyをさらに機能強化するライブラリ。統計や信号計算ができる
# - Pandas（パンダス）： データフレーム形式でさまざまなデータを加工するためのライブラリ
# - Matplotlib（マットプロットリブ）： データをグラフ化するためのライブラリ
# 
# これらの4つのライブラリは、データを前処理したり可視化したりするのに非常に便利なツールです。さまざまなライブラリの基礎となるものでもあり、本書で紹介する機械学習のScikit-learnなどのライブラリのベースにもなっています。以下の図は、それらのライブラリとの位置付けをイメージ化したものです。

# （※図は書籍を参照してください※）

# ### 2.1.1 ライブラリの読み込み
# 
# ライブラリは、Pythonのモジュールという機能で実装されています。利用するためには、モジュールを読み込む必要があります。モジュールを読み込むための構文はいくつかありますが、代表的な構文は、次の2つです。これらの構文を使ってモジュール（すなわちライブラリ）を読み込んで、利用できるようにすることをモジュールのインポートと言います。
# 下記において「識別名」は、プログラムからそのモジュールを参照するときの名称で、「属性」は、そのモジュールに含まれる機能のことです。
# 
# （1） `import` モジュール名 `as` 識別名
# 
# （2） `from` モジュール名 `import` 属性
# 
# #### importを使った例
# 
# 具体的に、`import`を使ってどのように記述するのかについては、それぞれのライブラリのところで説明しますが、ここで少し例を挙げます。
# たとえば、 Numpyを利用するには、次のように記述します。

# In[ ]:


import numpy as np

# これは、Numpyというモジュールを「`np`」という識別名でインポートするという意味です。
# モジュールは機能が階層化されており、「モジュール名.機能名.機能名.…」という書き方をすることで、その機能を実行できます。つまりこの例では、「`np`」という識別名を付けているので、以降のプログラムでは、「`np.機能名`」と記述することで、Numpyが提供する、さまざまな機能を利用できるようになります。
# 
# なお、この「`np`」という部分には、好きな名前を付けられます。`as`の後ろにどのような名前を指定するのは自由ですが、概ね、元々のライブラリ名を短縮したわかりやすい名前を使うのが慣例です。本書では「`import numpy as np`」としますが、他の文献では、別の名前で参照していることもあるので注意してください。

# #### fromを使ったインポート
# 
# 階層化しているライブラリでは、「モジュール名.機能名.機能名.…」のように、長く書かなければならなく不便です。それを一部省略するためには、`from`を使って、特定の機能だけ別名を付ける方法があります。
# たとえば、次のような方法です。

# In[ ]:


from numpy import random

# これは、Numpyが提供する`random`という機能（この機能は、あとで紹介するように、乱数と呼ばれるランダムな値を発生する機能です）だけを、以降、「`random.機能名`」という名前で使えるようにする構文です。
# つまり本来は、「`ny.random.機能名`」と記述する必要があるところを、「`random.機能名`」のように、簡易に書けるようになります。

# ### 2.1.2 マジックコマンド

# 1章で説明したように、Jupyter環境では、Pythonのプログラムを記述して、［Run］をクリックすると、その場で実行結果を表示できます。この章で説明するライブラリを使ったプログラムも例外ではありません。
# たとえば、Numpyを使って各種計算をすれば、その計算結果が表示されます。そして、Matplotlibを使ってグラフを描けば、そのグラフが表示されます。
# 
# このとき、「小数何桁まで表示する」とか「グラフを別画面に表示するか埋め込んで表示するか」などを指定することができると便利です。そこで一部のライブラリでは、こうした設定をJupyter環境（より正確にはJupyterが利用しているIPython環境）から簡単に指定できるよう、「マジックコマンド」という機能を備えています。
# 
# マジックコマンドとは、Jupyter環境において、さまざまな環境操作をするための命令で、「`%`」から始まるコマンドです。デフォルトでは、「外部コマンドの実行（`%run`）」「ファイルのコピー（`%cp`）」「時間の計測（`%time`）」などの機能が用意されています。
# 
# 一部のライブラリをインポートすると、このマジックコマンドが拡張され、ライブラリの動作の指定ができるようになります。
# 
# >［メモ］　標準のマジックコマンドは「ビルドインマジックコマンド」と呼ばれます。「`%quickref`」と入力して［Run］をクリックすると、一覧で表示できます。
# 
# この章で扱うライブラリのうち、NumpyとMatplotlibには、次の拡張マジックコマンドがあります。
# 
# - `%precision` 　Numpyによる拡張です。データを表示する際に、小数、第何桁まで表示するのかを指定します。
# - `%matplotlib`  Matplotlibによる拡張です。グラフなどの表示方法を指定します。「`inline`」と記述すると、その場所にグラフなどが表示されます。`%matplotolib`を指定しない場合は、別ウィンドウで表示されます。
# 
# これらの指定を使うと結果が見やすくなるので、本書では、適宜、これらのマジックコマンドを使っていきます。

# ### 2.1.3 この章で使うライブラリのインポート
# 
# この章では、Numpy、Scipy、Pandas、Matplotlibの各ライブラリを、次のようにしてインポートするものとします。それぞれの意味については、各ライブラリのところで改めて説明します。

# In[ ]:


# 以下のライブラリを使うので、あらかじめ読み込んでおいてください
import numpy as np
import numpy.random as random
import scipy as sp
import pandas as pd
from pandas import Series, DataFrame

# 可視化ライブラリ
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
%matplotlib inline

# 小数第3位まで表示
%precision 3

# ## 2.2 Numpyの基礎
# 
# キーワード：多次元配列、転置、行列の積、乱数、復元抽出、非復元抽出

# Numpyは、科学計算でもっともよく使われる基本的なライブラリです。多次元配列を処理することができるなど、機能的に優れているだけでなく、PythonではなくC言語で書かれたモジュールであり、処理が高速なのも特徴です。次の節で説明するScipyなどの数値計算ライブラリの基礎ともなっています。

# ### 2.2.1 Numpyのインポート

# ここでは、Numpyを次のようにしてインポートします。
# 1行目では、「`as np`」としているので、以降のプログラムでは、Numpyライブラリを「`np.機能名`」と表記することで使えます。
# そして2行目はマジックコマンドです。Jupyter環境において、結果を小数点何桁まで表示するのかという指定です。ここでは、小数第3位まで表示するようにしました。

# In[ ]:


# Numpyライブラリの読み込み
import numpy as np

# 小数第3位まで表示という意味
%precision 3

# ### 2.2.2 配列操作
# 
# Numpyの基本的な使い方を説明します。ここでは配列の作り方から説明します。

# #### 配列
# 
# まずは、1から10までの配列を作成してみましょう。Numpyにおいて、配列は`array`オブジェクトとして構成されます。これは、`np.array`のように、「インポートしたときに`as`の部分に付けた名前」と「`array`」をピリオドでつなげた名称で指定します。
# 10個の要素を持つ配列を作成する例を以下に示します。配列の要素として設定した値（9, 2, 3,…）は適当なもので、とくに意味はありません。なお、値を綺麗に並べていないのは、のちの例で、並べ替えをする処理を説明するためです。

# In[ ]:


# 配列の作成
data = np.array([9, 2, 3, 4, 10, 6, 7, 8, 1, 5])
data

# #### データ型
# Numpyで扱うデータは、高速に計算する目的で、また、計算中に値の精度を保つため、データの「型（`type`）」というものを持っています。
# データ型とは、「整数」や「浮動小数」などの値の種類のことで、次のような型があります。
# 間違った型を指定すると、目的の精度が出なかったり、処理速度が遅くなったりするので注意しましょう。とくに「整数」として扱うか「浮動小数」で扱うかによって、計算速度が大きく違います。なお、以下に8ビットや16ビットと記載がありますが、ビットとは0か1のどちらかをあらわす単位です。ビット数が大きいほど広範囲の値を表現できる反面、データを確保するための場所（メモリ）が大きくなると理解してください。

# ■`int` (符号付きの整数)
# 
# |データ型|概要|
# |:--|:--|
# |`int8`|8ビットの符号付き整数|
# |`int16`|16ビットの符号付き整数|
# |`int32`|32ビットの符号付き整数|
# |`int64`|64ビットの符号付き整数|

# ■`uint` (符号なしの整数)
# 
# |データ型|概要|
# |:--|:--|
# |`uint8`|8ビットの符号なし整数|
# |`uint16`|16ビットの符号なし整数|
# |`uint32`|32ビットの符号なし整数|
# |`uint64`|64ビットの符号なし整数|
# 

# ■`float` (浮動小数点数)
# 
# |データ型|概要|
# |:--|:--|
# |`float16`|16ビットの浮動小数点数|
# |`float32`|32ビットの浮動小数点数|
# |`float64`|64ビットの浮動小数点数|
# |`float128`|128ビットの浮動小数点数|
# 

# ■`bool` （真偽値）
# 
# |データ型|概要|
# |:--|:--|
# |`bool`|`True`か`False`で表される、真偽値|
# 

# 型を調べるには、変数の後ろに「`.dtype`」のように指定します。結果は、次のように「`int32`」と表示されます。これは32ビットの長さの整数型という意味です。

# In[ ]:


# データの型
data.dtype

# 「`.dtype`」という書き方は、「そのオブジェクトの`dtype`プロパティを参照する」という意味です。このようにピリオドで区切って、オブジェクトの状態を調べたり、オブジェクトが持つ機能（関数・メソッド・プロパティ）を実行したりするのは、オブジェクト型プログラミングの特徴です。
# 
# ちなみに、「.」を入力した後に <kbd>Tab</kbd>キーを押すと、その変数がもっているプロパティやメソッドの一覧が表示されるので、そこから該当のものを選ぶこともできます。そうすることで、すべてのプロパティやメソッドを正確に覚える必要がなくなり、タイプミスも減ります。

# <img src="figures/chap2_01_sitei.png">

# >**[ポイント]**
# >
# >作業（コーディング）を早く正確にするためには、<kbd>Tab</kbd>を使いなそう。

# #### 次元数と要素数
# 
# 配列の次元数と要素数を取得するには、それぞれ、`ndim`プロパティと`size`プロパティを参照します。これらのプロパティを確認すれば、データの大きさなどが、どのぐらいなのかがわかります。以下は次元数が1、要素数が10になっています。

# In[ ]:


print('次元数:', data.ndim)
print('要素数:', data.size)

# #### すべての要素に対する計算
# 
# 1章で見てきたように、Pythonにおいて、Numpyではない、ふつうの配列（リスト）の、すべての要素を係数倍にするには、`for`を使ったループ処理が必要です。
# しかしNumpyの場合は、たとえば2倍にするのであれば、次のように、配列に対して「`*2`」と記述するだけで、すべての要素が2倍になります。

# In[ ]:


# それぞれの数字を係数倍（ここでは2倍）
data * 2

# それぞれの要素での掛け算や割り算も、`for`文などを使わずに簡単に計算できます。

# In[ ]:


# それぞれの要素同士での演算
print('掛け算:', np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) * np.array([10, 9, 8, 7, 6, 5, 4, 3, 2, 1]))
print('累乗:', np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) ** 2)
print('割り算:', np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) / np.array([10, 9, 8, 7, 6, 5, 4, 3, 2, 1]))

# #### 並べ替え（ソート）
# 
# データを並べ替えるには、`sort`メソッドを使います。デフォルトでは、昇順（小さい数字から大きい数字）になります。

# In[ ]:


# 現在の値を表示
print('そのまま：', data)

# ソートした結果を表示
data.sort()
print('ソート後：', data)

# なお、`sort`メソッドは、元のデータ（`data`）を置き換えるので注意しましょう。再度`data`を表示すると、ソート後のデータになっているのがわかります。

# In[ ]:


print(data)

# 降順（大きい数字から小さい数字）にしたい場合は、`data[::-1].sort()`のように、**スライス**を使って操作します。
# スライスはPythonの機能で、`[n:m:s]`のように記述すると、「`n`番目から`m-1`番目を、`s`ずつ飛ばして取り出す」という意味になります。`n`や`m`を省略したときは「すべて」という意味になります。また`s`が負のときは先頭からではなく、末尾から取り出すことを意味します。つまり、`[::-1]`は、「末尾から1つずつ取り出す」という意味になります。つまり、`sort`メソッドを実行して昇順にした結果を逆順で取り出すので、最終的な結果として、その逆の降順としてデータを取り出せるということになります。

# In[ ]:


data[::-1].sort()
print('ソート後：', data)

# 並べ替えの補足説明として、昇順と降順どちらが大きい順番に並べるのか混乱する人が多いのですが、たとえば、降順は下に降りて行くので大きいもの順で、昇順は上に登って行くので小さいもの順だとイメージを持てば、覚えやすいです。
# 
# なお、sortメソッドはマーケティング用途では、ある店舗別の売り上げランキングやユーザーのWebサイトの訪問回数のランキング計算などに使うことができます。

# #### 最小、最大、合計、積上の計算
# Numpyのarrayデータは、`min`メソッドや`max`メソッドを呼び出すことで、最小値や最大値なども求めることができます。`cumsum`というメソッドは積上（前から順に足し上げていく）演算です。0番目の要素はそのまま、1番目の要素は0番目の要素+1番目の要素、2番目の要素は0番目の要素+1番目の要素+2番目の要素、…、という具合に足し上げたものです。

# In[ ]:


# 最小値
print('Min:', data.min())
# 最大値
print('Max:', data.max())
# 合計
print('Sum:', data.sum())
# 積み上げ
print('Cum:', data.cumsum())
# 積み上げ割合
print('Ratio:', data.cumsum() / data.sum())

# ### 2.2.3 乱数
# 
# 乱数とは、簡単にいうと、規則性のないデタラメな数をいいます。データ分析において、収集したデータをランダムに分離したり、ランダムな値を加えてばらつきを出したりするときに使います。
# 乱数の機能はPythonにもありますが、データ分析の分野ではNumpyの乱数機能を使うことが多いです。
# Numpyをインポートしているのであれば、「`np.random`」のように記述することで、Numpyの乱数機能を使えます。

# また、インポートするときに次のように記述すれば、もし「`np.random`」と記述する代わりに、「`np.`」を省略して「`random`」と略記できます。以下では、このようにインポートして、「`random.機能名`」と書くだけで、乱数の機能が使えるようにしたことを前提でプログラムを記述します。

# In[ ]:


import numpy.random as random

# #### 乱数のシード
# 
# 乱数はまったくのランダムな数というわけではなく、疑似乱数と呼ばれるもので、数式によってランダムな値を作り出すものです。そのランダムな値の初期値を**シード**と言い、`random.seed`を使って指定できます。
# たとえば、次のようにシードを「0」に設定します。

# In[ ]:


random.seed(0)

# `random.seed`の呼び出しは必須ではありませんが、同じシード値を指定した場合は、何度実行しても、同じ乱数が得られることが担保されます。データ分析では、まったくのランダムな値が得られてしまうと、解析結果が、都度変わってしまう可能性があります。データ分析では、後から検証することが多いので、その一貫性を担保するために、シードを設定することが多いです。シード値を設定しておくと実行のたびに結果が変わってしまうことがありません。
# 
# #### 乱数の発生
# 
# 乱数と一口にいっても、実はさまざまな乱数があり、Numpyでそれらを作成できます。たとえば、平均0、標準偏差1の正規分布の乱数を取得するには、`random.randn`を使います。次の例は、そのような10個の乱数を得る例です。

# In[ ]:


random.seed(0)

# 正規分布（平均0、分散1）の乱数を10個発生 
rnd_data = random.randn(10)

print('乱数10個の配列:', rnd_data)

# `randn`以外にも、次に示す機能があり、どのような種類の乱数が欲しいのかによって、適切なものを選ぶようにします。分布については、第4章の確率統計で学びます。

# | 機能 | 意味 |
# |:---------|:-------|
# | `rand` | 一様分布。0.0以上、1.0未満 |
# | `random_sample` | 一様分布。0.0以上、1.0未満（`rand`とは引数の指定方法が異なる） |
# | `randint` | 一様分布。任意の範囲の整数 |
# | `randn` | 正規分布。平均0、標準偏差1の乱数 |
# | `normal` | 正規分布。任意の平均、標準偏差の乱数 |
# | `binomial` | 二項分布の乱数 |
# | `beta` | ベータ分布の乱数 |
# | `gamma` | ガンマ分布の乱数 |
# | `chisquare` | カイ二乗分布の乱数 |

# #### データのランダムな抽出
# 
# データサイエンスにおいて、与えられたデータ列から、ランダムなものを取り出す操作はよく行われます。そのようなときは、`random.choice`を使います。`random.choice`には、2つの引数と1つのオプションを指定します。1つ目の引数は、操作対象の配列、2つ目は取り出す数です。オプションは`replace`です。`replace`を`True`にする、もしくは省略したときは、取り出すときに重複を許します。これを**復元抽出**と言います。`replace`を`False`にしたときは、データの重複を許さずに取り出します。これを**非復元抽出**と言います。

# In[ ]:


# 抽出対象データ
data = np.array([9,2,3,4,10,6,7,8,1,5])

# ランダム抽出
# 10個を抽出（重複あり、復元抽出）
print(random.choice(data, 10))
# 10個を抽出（重複なし、非復元抽出)
print(random.choice(data, 10, replace = False)) 

# 復元抽出では、同じ数字が何個かありますが、非復元抽出では、同じ数字が入ることはありません。

# >**[やってみよう]**
# >
# >`seed(0)`の`0`を変えたり、ランダム抽出の数を増やしたりして、結果がどう変化するのかを確認しましょう。

# #### ■コラム　Numpyは高速

# Numpyは計算速度が速いのも特徴です。どのぐらい速いのか計測してみましょう。次の例は、乱数を$10^6$個発生させて、それを合計する実装です。
# 「`sum(normal_data)`」が普通の処理、「`np.sum(numpy_random_data)`」がNumpyを使った処理です。

# In[ ]:


# Nは乱数の発生数、10の6乗
N = 10**6

# Python版 (以下のrange(N)は0からN-1までの整数を用意しています。 
# 「_」は、代入した値を参照しないときに使う慣例的な変数名です。
# たとえば、for a in range(N)と書くのと同じですが、aと書くと、その値をあとで使うように見えるので、
# その値を参照しないときは、for _ in range(N)のように慣例的に書く書き方です
normal_data = [random.random() for _ in range(N)]

# Numoy版
numpy_random_data = np.array(normal_data)

# calc time :合計値
# ふつうの処理
%timeit sum(normal_data)

# Numpyを使った処理
%timeit np.sum(numpy_random_data)

# 普通に演算するよりも、Numpyを使った方（`np.sum()`）が速いことがわかります。
# `%timeit`は100回同じ処理をして、ベスト3の平均計算時間を返すマジックコマンドです（Jupyter環境でRunを実行すると、100回実行されるのですから、その実行結果が表示されるまでには、しばらく時間がかかりますが、それは正常な動作です）。
# たとえば、「`100 loops, best of 3: 5.78 ms per loop`」と表示されたときは、100回計算して、ベスト3の計算時間平均が5.78ミリ秒という意味です。
# 実行回数と平均回数は、それぞれ`n`オプションと`r`オプションで変更できます。たとえば、「`%timeit -n 10000 -r 5 sum(normal_data)`」のようにすれば、1万回、ベスト5の平均計算時間という意味になります。なお、msはミリ秒で、µsはマイクロ秒（ミリ秒の1000分の1）です。

# >**[ポイント]**
# >
# >処理を高速化したいときは、`%timeit` を使いながら、計算時間をチェックしましょう。

# ### 2.2.4 行列

# Numpyを使うと行列計算もできます。
# まずは、行列の作成方法から説明します。次の例は、0〜8までの数字を3×3行列で表現するものです。`arange`関数は指定した連続した整数を発生する機能を持ちます。`arrange(9)`とした場合、0から8までの整数を発生します。それを`reshape`関数で3×3の行列に分割しています。
# これで変数`array1`に3×3の行列が作られます。

# In[ ]:


np.arange(9)

# In[ ]:


# データの準備
array1 = np.arange(9).reshape(3,3)
print(array1)

# 行列から、行や列のみを抜き出したいときは、「[行範囲:列範囲]」のように表記します。それぞれの範囲は、「開始インデックス,終了インデックス」のように、カンマで区切って指定します。開始インデックスや終了インデックスを省略したときは、それぞれ「最初から」「末尾まで」という意味になります。
# たとえば、次のように「`[0,:]`」を指定すると、「行は1行目」「列はすべて」という意味になるので、1行目のすべての列を取り出すことができます。なお、インデックスは0からはじまりますが、対象の行列は1からはじまるので注意しましょう。

# In[ ]:


# 1行目
array1[0,:]

# 1列目のすべての行を取り出すには、「`[:,0]`」を指定します。これは「列は1列目」「行はすべて」という意味です。

# In[ ]:


# 1列目
array1[:,0]

# #### 行列の演算
# 
# 行列の掛け算をしてみましょう。この計算方法がわからない方は、線形代数の復習をしてください。
# 
# まずは、掛け算する対象とする行列を作成しましょう。次の例では、3×3の行列を作成し、変数`array2`に代入しています。

# In[ ]:


array2 = np.arange(9,18).reshape(3,3)
print(array2)

# この行列と、先の`array1`の行列を掛け算してみましょう。
# 行列の掛け算では、`dot`関数を使います。間違えて`*`を使うと、行列の掛け算ではなく、それぞれの要素を掛け算してしまうので、注意しましょう。

# In[ ]:


# 行列の積
np.dot(array1, array2)

# In[ ]:


# 要素どうしの積
array1 * array2

# #### 要素が0や1の行列を作る
# 
# データ分析では、要素が0や1の行列を作りたいことがあります。その場合、「`[0, 0, 0, 0, 0…]`」のようにひとつずつ要素を記述する（もしくは`for`文を使って繰り返し処理で作る）のは大変なので、専用の構文が用意されています。
# 次のように「`np.zeros`」を指定すると、すべての要素が0の行列を作れます。同様に「`np.ones`」は、すべての要素が1の行列を作ります。`dtype`オプションでは、データの型を指定します。`int64`は64ビット整数、`float64`は64ビット浮動小数です。次のコードは、要素がすべて0（`int64`）の2行3列の行列、要素がすべて1（`float64`）の2行3列の行列を、それぞれ作成する例です。

# In[ ]:


print(np.zeros((2, 3), dtype = np.int64))
print(np.ones((2, 3), dtype = np.float64))

# #### <練習問題 2-1>
# 
# 
# 1から50までの自然数の和を計算するプログラムを書いて、最後の計算結果を表示させるプログラムを書いてください。ただし、np.arrayで1から50までの配列を作り、その総和を求める方法で計算してください。

# #### <練習問題 2-2>
# 
# 標準正規分布に従う乱数を10個発生させて配列を作成してください。また、その中での最小値、最大値、合計を求めるプログラムを書いてください。

# #### <練習問題 2-3>
# 
# 要素がすべて3の5行5列の行列を作成し、その行列の2乗をする計算をしてみましょう。

# ## 2.3 Scipyの基礎
# キーワード：逆行列、固有値、固有ベクトル、最適化

# Scipyは、科学技術計算をするためのライブラリで、多様な数学処理（線形代数の計算、フーリエ変換など）ができます。
# ここでは、線形代数の逆行列や固有値、方程式の解などを求めてみましょう。なお、これらの用語がわからない方は、ネットで調べるか、1章で紹介した線形代数の参考書等で学習してください。

# ### 2.3.1 Scipyのライブラリのインポート
# 
# ここでは、Scipyの線形代数用のライブラリをインポートします。
# 前述の「2.1.3 この章で使うライブラリのインポート」において、「`import scipy as sp`」としてScipyをすでにインポートしていますが、ここで「`as sp`」としているので、「`sp.機能名`」と表記することでScipyライブラリを使えるようになっています。
# 
# 以下ではさらに、線形代数用のライブラリを`linalg`、最適化計算（最小値）用の関数を`minimize_scalar`のように、より短い名前で使えるようにします。

# In[ ]:


# 線形代数用のライブラリ
import scipy.linalg as linalg

# 最適化計算（最小値）用の関数
from scipy.optimize import minimize_scalar

# ### 2.3.2 行列計算

# #### 行列式と逆行列の計算
# 
# まずは行列式を計算する例です。次のように`det`関数を使います。

# In[ ]:


matrix = np.array([[1,-1,-1], [-1,1,-1], [-1,-1,1]])

# 行列式
print('行列式')
print(linalg.det(matrix))

# 逆行列を計算するには、`inv`関数を使います。

# In[ ]:


# 逆行列
print('逆行列')
print(linalg.inv(matrix))

# 値が正しいかどうかを確認してみましょう。もとの行列と逆行列の積は、単位行列のはずです。次のようにして積を求めると、確かに単位行列となっていることがわかります。

# In[ ]:


print(matrix.dot(linalg.inv(matrix)))

# #### 固有値と固有ベクトル
# 
# 次に、固有値と固有ベクトルを計算してみましょう。`linalg`の`eig`関数を実行すると求められます。

# In[ ]:


# 固有値と固有ベクトル
eig_value, eig_vector = linalg.eig(matrix)

# 固有値と固有ベクトル
print('固有値')
print(eig_value)
print('固有ベクトル')
print(eig_vector)

# ### 2.3.3 ニュートン法

# 最後に、最適化計算を使う方法を説明します。
# 
# #### 方程式の解を求める
# 
# まずは、方程式の解を求めてみましょう。ここでは、次の2次関数の解を求めることを考えます。

# \begin{eqnarray}
# f(x) = x^2 + 2x +1
# \end{eqnarray}

# この解は紙と鉛筆で計算することも可能で、解は-1ですが、ここでは解の近似計算でよく使われるニュートン法を使って求めてみましょう。まずは、上の関数をPythonの関数として定義します。

# In[ ]:


# 関数の定義
def my_function(x):
    return (x**2 + 2*x + 1)

# 次に、$f(x)=0$の解$x$を求めるために、以下で`newton`関数を使います。`newton`関数の1つ目の引数として、いま作成した`my_function`関数をセットし、2つ目の引数には、解を決める条件式となる$f(x)=0$ の$0$をセットします。

# In[ ]:


# ニュートン法の読み込み
from scipy.optimize import newton

# 計算実行
print(newton(my_function,0))

# 結果は上記のように、ほぼ-1になっている（数値計算をしているため）ことがわかります。

# なお、ニュートン法をはじめて聞いた方は検索をするか、数学の専門書で、最適化や数値計算のコーナーで探してみてください。

# #### 最小値を求める
# 
# 次に、この同じ関数$f(x)$における、最小値を求めることを考えます。
# ここでは、`minimize_scalar`関数を使って、下記のようにします。ここで指定している`method`というパラメータで指定している「`Brent`」は、Brent法を使うことを示します。Brent法とは、放物線補間法と黄金分割法（単峰関数の極値、つまり極大値または極小値を求める方法）を組み合わせた方法で、黄金分割法よりも収束が速いのが特徴です。
# 本書では、あまり使わないので、用語等については覚えなくても大丈夫ですが、これら以外にも、さまざまなアプローチ方法があるので、時間がある方は調べてみてください。

# In[ ]:


# 計算実行
print(minimize_scalar(my_function, method = 'Brent'))

# 　Scipyは、積分や微分法的式などにも使えますが、この章では、いったんこれで終わりにします。Scipyを使った、さまざまな科学計算については、後の章で改めて説明します。

# >**[やってみよう]**
# >
# >`my_function`関数の計算式を$f(x)=0$から、さまざまな関数に変更して、最小値などの計算を実行してみましょう。

# #### <練習問題 2-4>
# 
# 以下の行列について、行列式を求めてください。
# 
# $
#   A = \left(
#     \begin{array}{ccc}
#       1 & 2 & 3 \\
#       1 & 3 & 2 \\
#       3 & 1 & 2
#     \end{array}
#   \right)
# $

# #### <練習問題 2-5>
# 
# <練習問題 2-4>と同じ行列について、逆行列、固有値と固有ベクトルを求めてください。

# #### <練習問題 2-6>
# 
# 以下の関数が0となる解を、ニュートン法を用いて求めてみましょう。

# \begin{eqnarray}
# f(x) = x^3 + 2x+ 1
# \end{eqnarray}

# ## 2.4 Pandasの基礎
# キーワード：インデックス、Series、DataFrame、データの操作、データの結合、ソート

# PandasはPythonでモデリングする（機械学習等を使う）前のいわゆる前処理をするときに便利なライブラリです。さまざまなデータのさまざまな加工処理をスムーズに柔軟に実施することができ、表計算やデータの抽出、検索などの操作ができるようになります。具体例を挙げると、データの中からある条件（男性だけ）を満たす行を抽出したり、ある軸（男女別など）を設定してそれぞれの平均値（身長、体重など）を算出したり、データを結合するなどの操作ができます。DB（データベース）のSQLに慣れている方には扱いやすいと思います。

# ### 2.4.1 Pandasのライブラリのインポート
# 
# ここでは、Pandasのライブラリをインポートします。
# 前述の「2.1.3 この章で使うライブラリのインポート」において、「`import pandas as pd`」としてPandasをインポートしているので、「`pd.機能名`」と表記することでPandasライブラリを使えるようになっています。
# 
# 以下ではさらに、一次元の配列を扱うときの`Series`ライブラリと、二次元の配列を扱うときの`DataFrame`ライブラリをインポートします。

# In[ ]:


from pandas import Series, DataFrame

# ### 2.4.2 Seriesの使い方
# 
# Seriesは1次元の配列のようなオブジェクトです。PandasのベースはNumpyの`array`です。以下に、`Series`オブジェクトに10個の要素を設定する、簡単な例を示します。
# 実行結果を見ると分かるように、`Series`オブジェクトを`print`すると、2つの組の値が表示されます。先頭の10行文は要素のインデックスと値です。`dtype`はデータの型です。

# In[ ]:


# Series
sample_pandas_data = pd.Series([0,10,20,30,40,50,60,70,80,90])
print(sample_pandas_data)

# インデックスは要素を特定するキーのことです。この例のように、`[0, 10, 20, 30, 40,…]`のように`Series`オブジェクトに対して、値だけを指定した場合、インデックスは先頭から0、1、2…のように連番が付きます。
# データの値とインデックスの値は、それぞれ次のように、`values`プロパティと`index`プロパティを指定することで、別々に取り出すこともできます。

# In[ ]:


print('データの値:', sample_pandas_data.values)
print('インデックスの値:', sample_pandas_data.index)

# インデックスには任意の数値の範囲を指定できるほか、特定の文字にすることもできます。インデックスとは、ラベル（索引、見出し）のようなもので、このようなラベルを付けることで、データ検索等がしやすくなります。
# 以下は、それぞれの要素に、`a`、`b`、`c`、…というインデックスを付けて値を格納したデータの例です。

# In[ ]:


# indexをアルファベットでつける
sample_pandas_index_data = pd.Series(
    [0, 10,20,30,40,50,60,70,80,90],
    index=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])
print(sample_pandas_index_data)

# In[ ]:


print('データの値:', sample_pandas_index_data.values)
print('インデックスの値:', sample_pandas_index_data.index)

# ### 2.4.3 DataFrameの使い方
# 
# `DataFrame`オブジェクトは2次元の配列です。それぞれの列で、異なる`dtype`（データ型）を持たせることもできます。
# 下記は、`ID`、`City`、`Birth_year`、`Name`の4つの列を持つデータ構造を示した例です。`print`関数で表示すると、そのデータは表形式で表示されます。

# In[ ]:


attri_data1 = {'ID':['100','101','102','103','104'],
               'City':['Tokyo','Osaka','Kyoto','Hokkaido','Tokyo'],
               'Birth_year':[1990,1989,1992,1997,1982],
               'Name':['Hiroshi','Akiko','Yuki','Satoru','Steve']}

attri_data_frame1 = DataFrame(attri_data1)

print(attri_data_frame1)

# 一番左列に表示されている`0, 1, 2, 3, 4`の値は、インデックスの値です。`DataFrame`オブジェクトも`Series`オブジェクトと同様にインデックスを変更したり、インデックスとして文字を指定したりすることもできます。
# 次のようにインデックスを指定すると、`attri_data_1`の値に対して新しいインデックスを指定した`attri_data_frame_index1`という`DataFrame`オブジェクトを作ることができます（ここでは`DataFrame`オブジェクトに対して操作しましたが、`Series`も同様の操作で、何か他の`Series`オブジェクトからインデックスを変更した`Series`オブジェクトを作ることができます）。

# In[ ]:


attri_data_frame_index1 = DataFrame(attri_data1,index=['a','b','c','d','e'])
print(attri_data_frame_index1)

# #### Jupyter環境におけるデータ表示
# 
# ここまでは`Series`オブジェクトや`DataFrame`オブジェクトを表示する際に、`print(attri_data_frame_index1)`のように`print`関数を使ってきました。しかしデータの変数を、そのまま次のように記述することで、表示することもできます。
# この場合、Jupyter環境によって、これが`Series`オブジェクトや`DataFrame`オブジェクトであることが認識され、罫線などが付いた見やすい表示になります。
# 以下では、この方法で表示していきます。

# In[ ]:


attri_data_frame_index1

# ### 2.4.4 行列操作
# 
# DataFrameは、さまざまな行列操作ができます。
# 
# #### 転置
# 
# 行列の転置のように、行と列を入れ替える場合には、`.T`メソッドを使います。

# In[ ]:


# 転置
attri_data_frame1.T

# #### 特定列のみを取り出す
# 
# 特定の列だけを指定したいときは、データの後にその列名を指定します。複数の列を指定したいときは、それらをPythonのリストの形式で指定します。

# In[ ]:


# 列名の指定（1つの場合）
attri_data_frame1.Birth_year

# In[ ]:


# 列名の指定(複数の場合)
attri_data_frame1[['ID', 'Birth_year']]

# ### 2.4.5 データの抽出
# 
# `DataFrame`オブジェクトでは、特定の条件を満たすデータだけを取り出したり、複数のデータを結合したりすることもできます。
# 
# 次の例は、データのうち、`City`が`Tokyo`のみのデータを抽出する例です。ここで指定している条件である`attri_data_frame1['City'] == 'Tokyo'`は、`dtype`が`bool`である`Series`オブジェクトです。この処理は、`attri_data_frame1['City'] == 'Tokyo'`が`True`であるデータをすべて`attri_data_frame1`から抽出するもので、フィルターの役割を果たしています。

# In[ ]:


#　条件（フィルター）
attri_data_frame1[attri_data_frame1['City'] == 'Tokyo']

# なお、条件部分である式はCity列の要素1つ1つとTokyoを比較しており、以下のようにそこだけ取り出して表示すると、`True`か`False`になっていることがわかります。

# In[ ]:


attri_data_frame1['City'] == 'Tokyo'

# 条件を複数指定したいときは、次のように`isin`（リスト）を使います。以下は、CityがTokyoかOsakaであるデータを抽出しています。この使い方は、あとの章でも使います。

# In[ ]:


#　条件（フィルター、複数の値）
attri_data_frame1[attri_data_frame1['City'].isin(['Tokyo','Osaka'])]

# >**[やってみよう]**
# >
# >他にも条件を変更（`Birth_year`が1990未満など）して、フィルターを実行してみましょう。

# ### 2.4.6 データの削除と結合
# 
# `DataFrame`オブジェクトでは、必要のない列や行を削除したり、他の`DataFrame`オブジェクトと結合したりすることもできます。
# 
# #### 列や行の削除
# 
# ある特定の列や行を削除するには`drop`メソッドを実行します。`axis`パラメータに軸を指定します。「`axis=0`が行」「`axis=1`が列」です。なお、この`axis`パラメータは他の場面でも使うので、覚えておいてください。
# 
# 
# ・行削除の場合：1つ目の引数に削除したい行のインデックスをリストとして指定します。`axis`パラメータには「`0`」を指定します。
#  
# ・列の削除の場合：1つ目の引数に削除したい列名をリストとして指定します。`axis`パラメータには「`1`」を指定します。
#  
#  次の例は、`Birth_year`列を削除する例です。

# In[ ]:


# データの列の削除
attri_data_frame1.drop(['Birth_year'], axis = 1)

# なお、上記で列を削除しても元のデータの列が削除されたわけではないので、注意しましょう。置き換えたい場合は、あらためて`attri_data_frame1 = attri_data_frame1.drop(['Birth_year'],axis=1)`のように設定します。もしくは、オプションの`inplace=True`をパラメータとして指定すると、元のデータを置き換えることもできます。

# #### データの結合
# 
# `DataFrame`オブジェクト同士は結合できます。データ分析ではさまざまなデータがある場合に、それらを結合して分析することは多々ありますから、実行できるようになりましょう。まずは例として、結合先の`DataFrame`オブジェクトを、次のように`attri_data_frame2`という変数で用意します。

# In[ ]:


# 別のデータの準備
attri_data2 = {'ID':['100','101','102','105','107'],
               'Math':[50,43,33,76,98],
               'English':[90,30,20,50,30],
               'Sex':['M','F','F','M','M']}
attri_data_frame2 = DataFrame(attri_data2)
attri_data_frame2

# そして、これまで使ってきた`attri_data_frame1`と、この`attri_data_fame2`を結合してみます。
# 結合するには`merge`メソッドを使います。キーを明示しないときは、自動で同じキーの値であるものを見つけて結合します。
# この例の場合、キーは`ID`です。`100`、`101`、`102`が共通であるため、それが合致するデータが結合されます。

# In[ ]:


# データのマージ（内部結合、詳しくは次の章で）
pd.merge(attri_data_frame1,attri_data_frame2)

# ### 2.4.7 集計
# 
# `DataFrame`オブジェクトでは、データを集計することできます。
# さらに`groupby`メソッドを使うと、ある特定の列を軸とした集計ができます。以下は「`Sex`の列」を軸として、数学のスコア平均を算出する例です。スコア平均を計算するには`mean`メソッドを使います。ほかにも、最大値を計算する`max`メソッドや最小値を計算する`min`メソッドなどもあります。

# In[ ]:


# データのグループ集計(詳しくは次の章で)
attri_data_frame2.groupby('Sex')['Math'].mean()

# >**[やってみよう]**
# >
# >他にも変数を変えて、実行してみましょう。集計対象を`English`にした場合はどうなりますか。また、最大値や最小値を求めてみましょう。

# ### 2.4.8 値のソート
# 
# `Series`オブジェクトや`DataFrame`オブジェクトのデータは、ソートすることもできます。値だけではなく、インデックスをベースにソートできます。
# 
# まずはソート対象のサンプルデータを次のように定義します。ソートの効果がわかりやすくなるよう、わざとデータを適当な順で並べてあります。

# In[ ]:


# データの準備
attri_data2 = {'ID':['100','101','102','103','104'],
               'City':['Tokyo','Osaka','Kyoto','Hokkaido','Tokyo'],
               'Birth_year':[1990,1989,1992,1997,1982],
               'Name':['Hiroshi','Akiko','Yuki','Satoru','Steve']}
attri_data_frame2 = DataFrame(attri_data2)
attri_data_frame_index2 = DataFrame(attri_data2,index=['e','b','a','d','c'])
attri_data_frame_index2

# インデックスでソートするには、次のように`sort_index`メソッドを実行します。

# In[ ]:


# indexによるソート
attri_data_frame_index2.sort_index()

# 値でソートする場合には、次のように`sort_values`メソッドを使います。

# In[ ]:


# 値によるソート、デフォルトは昇順
attri_data_frame_index2.Birth_year.sort_values()

# ### 2.4.9 nan（null）の判定
# 
# データ分析ではデータが欠損しており、該当のデータが存在しないことがあります。それらをそのまま計算すると、平均などを求めたときに正しい値が得られないので、除外するなどの操作が必要です。欠損値などのデータは`nan`という特別な値で格納されるので、その扱いについて補足します。
# 
# #### 条件に合致したデータの比較
# 
# まずは`nan`の話ではなく、ふつうに条件検索する例から説明します。
# 次の例は、`attri_data_frame_index2`の全要素を対象に、`Tokyo`という文字列があるかどうかを`isin`で調べる例です。その結果は、それぞれのセルに`True`か`False`が返されます。入っていれば（条件を満たしていれば）`True`、入っていなければ（条件を満たしていなければ）`False`が設定されます。この操作が、条件に合致するデータを探すときの基本です。

# In[ ]:


# 値があるかどうかの確認
attri_data_frame_index2.isin(['Tokyo'])

# #### nanとnullの例
# 
# 次の例は、`Name`列の値をわざと`nan`に設定した例です。`nan`かどうかを判定するには`isnull`メソッドを使います。

# In[ ]:


#　欠損値の取り扱い
# name をすべてnanにする
attri_data_frame_index2['Name'] = np.nan
attri_data_frame_index2.isnull()

# そして`nan`であるものの総数を求めるには、次のようにします。Nameが5になっているのは、上記の結果でわかるように、Trueが5つあるため、それをカウントしているからです。

# In[ ]:


# nullを判定し、合計する
attri_data_frame_index2.isnull().sum()

# 以上で、Pandasの簡単な説明は終わりです。3章では実際のデータの加工処理をしていきますので、ここで学んだことはしっかりと身につけてください。

# #### <練習問題 2-7>
# 
# 以下のデータに対して、`Money`が500以上の人を絞り込んで、レコードを表示してください。

# In[ ]:


from pandas import Series,DataFrame
import pandas as pd

attri_data1 = {'ID':['1','2','3','4','5'],
               'Sex':['F','F','M','M','F'],
               'Money':[1000,2000,500,300,700],
               'Name':['Saito','Horie','Kondo','Kawada','Matsubara']}

attri_data_frame1 = DataFrame(attri_data1)

# #### <練習問題 2-8>
# 
# <練習問題 2-7>のデータに対して、男女別（`MF`別）の平均`Money`を求めてください。

# #### <練習問題 2-9>
# 
# <練習問題 2-7>のデータに対して、以下のデータの同じ`ID`の人をキーとして、データをマージしてください。そして、`Money`と`Math`と`English`の平均を求めてください。

# In[ ]:


attri_data2 = {'ID':['3','4','7'],
               'Math':[60,30,40],
               'English':[80,20,30]}

attri_data_frame2 = DataFrame(attri_data2)

# ## 2.5 Matplotlibの基礎
# キーワード：データビジュアライゼーション、散布図、ヒストグラム

# データ分析をする上で、対象となるデータを可視化することはとても重要です。単に数字を眺めているだけでは、データに潜む傾向がなかなか見えなかったりしますが、データをビジュアル化することで、データ間の関係性なども見えてきます。特に、近年はインフォグラフィックスなどといって、可視化が注目されています。
# ここでは、主に`Matplotlib`と`Seaborn`を使って、データを可視化する基本的な方法を身につけましょう。巻末の参考URL「B-5」が参考になります。

# ### 2.5.1 Matplotlabを使うための準備
# 
# 前述の「2.1.3 この章で使うライブラリのインポート」において、MatplotlibとSeabornをすでにインポートしています。
# 
# Matplotlibでは、描画に関するほとんどの機能が「`pyplot.機能名`」で提供されています。そこで「2.1.3 この章で使うライブラリのインポート」では「`import matplotlib.pyplot as plt`」とインポートし、「`mpl.pyplot.機能名`」とフルネームで書くのではなく「`plt.機能名`」と略記できるようにしています。
# 
# `Seaborn`は`Matplotlib`のグラフを、さらにきれいにするライブラリです。インポートするだけでグラフがきれいになり、また、いくつかの追加のスタイルを指定できるようになります。
# 
# 以下の「`%matplotlib inline`」は、Jupyter Notebook上にグラフを表示するためのマジックコマンドです。Jupyter環境の初学者の方はグラフを書くときに忘れやすいので、注意しましょう。

# In[ ]:


# Matplotlib と Seabornの読み込み
# Seabornはきれいに図示できる
import matplotlib as mpl
import seaborn as sns

# pyplotにはpltの別名で実行できるようにする
import matplotlib.pyplot as plt

# Jupyter Notebook上でグラフを表示させるために必要なマジックコマンド
%matplotlib inline

# ### 2.5.2 散布図
# 
# Matplotlabでは、さまざまなグラフを描けますが、まずは、散布図から始めましょう。散布図は、2つの組み合わせデータに対して、`x−y`座標上に点をプロットしたグラフです。`plt.plot(x, y, 'o')`で描写でき、最後の引数はグラフの形状を指定するもので`'o'`は点で描くという意味です。その他の動作については、コード中のコメントを参考にしてください。
# 
# 散布図を描くと、2変数の関係性などが見えてきます。

# In[ ]:


# 散布図
import numpy.random as random

#　シード値の固定
random.seed(0)

# x軸のデータ
x = np.random.randn(30)

# y軸のデータ
y = np.sin(x) + np.random.randn(30)

# グラフの大きさ指定（20や6を変更してみてください）
plt.figure(figsize=(20, 6))

# グラフの描写
plt.plot(x, y, 'o')

#以下でも散布図が描ける
#plt.scatter(x, y)

# タイトル
plt.title('Title Name')
# Xの座標名
plt.xlabel('X')
# Yの座標名
plt.ylabel('Y')

# grid（グラフの中にある縦線と横線）の表示
plt.grid(True)

# 連続した値を与えれば、`plot`による描画は点ではなく曲線に見えます。たとえば次の例は、時系列など連続した（厳密には連続とみなした）曲線を描くものです。

# In[ ]:


# 連続曲線

# シード値の指定
np.random.seed(0)

# データの範囲
numpy_data_x = np.arange(1000)

# 乱数の発生と積み上げ
numpy_random_data_y = np.random.randn(1000).cumsum()

# グラフの大きさを指定
plt.figure(figsize=(20, 6))

# label=とlegendでラベルをつけることが可能
plt.plot(numpy_data_x, numpy_random_data_y, label='Label')
plt.legend()

plt.xlabel('X')
plt.ylabel('Y')
plt.grid(True)

# ### 2.5.3 グラフの分割
# 
# `subplot`を使うと、グラフを複数に分けることができます。以下は、2行1列のグラフを作成し、1番目と2番目と番号を指定して表示する例です。なお、`linspace(-10,10,100)`は$-10$から$10$までの数を$100$個に分割した数字リストを取り出すものです。

# In[ ]:


# グラフの大きさを指定
plt.figure(figsize=(20, 6))

# 2行1列のグラフの1つ目
plt.subplot(2,1,1)
x = np.linspace(-10, 10,100)
plt.plot(x, np.sin(x)) 

# 2行1列のグラフの2つ目
plt.subplot(2,1,2)
y = np.linspace(-10, 10,100)
plt.plot(y, np.sin(2*y)) 

plt.grid(True)

# ### 2.5.4 関数グラフの描画
# 
# 次は、「2.2.3　ニュートン法」で扱った
# 
# \begin{eqnarray}
# f(x) = x^2 + 2x +1
# \end{eqnarray}
# 
# の二次関数をグラフで表示する例です。このようにグラフにすると、$y=0$ と交わる近辺が$-2.5～0$の範囲であるので、この数値計算しなくても、解がおおよそ、この範囲にあることがわかります。

# In[ ]:


# 関数の定義（Scipyで使った二次関数の例と同じ）
def my_function(x):
    return x ** 2 + 2 * x + 1

x = np.arange(-10, 10)
plt.figure(figsize = (20, 6))
plt.plot(x, my_function(x)) 
plt.grid(True)

# ### 2.5.5 ヒストグラム
# 
# 次のグラフは、ヒストグラムと言われ、それぞれの値の**度数**（値が出現する回数）を示します。データの全体像を観察するときに使われる図です。データ分析では、このグラフを見て、どんな数値が多いのか、少ないのか、偏りがあるのかないのかを読み解きます。
# 
# 下記のように`hist`メソッドを使うと、ヒストグラムを描けます。括弧内に指定しているパラメータは、先頭から順に、「対象となるデータ」「ビンの数（幅、個数）」「範囲」です。

# In[ ]:


# シードの固定
random.seed(0)

# グラフの大きさ指定
plt.figure(figsize = (20, 6))

# ヒストグラムの描写
plt.hist(np.random.randn(10 ** 5) * 10 + 50, bins = 60, range = (20, 80))

plt.grid(True)

# `hist`メソッドには他にも、さまざまなパラメータがあります。次のように「?」を使うと、利用できるパラメータを確認できます。

# In[ ]:


?plt.hist

# また、`help`を使うと、どのような機能であるかを確認することもできます。`?`はJupyter環境（より正確にはIPython）独自の機能ですが、`help`はPythonの標準機能です。

# In[ ]:


help(plt.hist)

# これで、Matplotlibの基礎は終わりです。
# グラフを可視化するには、Matplotlib以外にPandasで描写する方法もあります。それについては、7章のデータ可視化の個所で少し触れます。
# 
# 
# データ分析で使うPyhonのメインライブラリ（Numpy、Scipy、Pandas、Matplotlib）の基本的な紹介については、これで終わりです。お疲れ様でした。
# この章で学んだテクニックは、次の3章の記述統計で使ったり、さらに別の章でも活用していきます。

# ### コラム さまざまなデータのビジュアル化
# 
# データのビジュアル化は、Python以外にも、さまざまなプログラミング言語、ライブラリで実現されており、Pythonでグラフ化するときの参考にもなります。
# たとえばJavaScriptには、さまざまな図を描ける「D3.js」というライブラリがあり人気です。これはPythonとは関係なくJavaScriptで使うものですが、データを多方向から見せてビジュアル化するという意味では勉強になります。
# 

# （※図は書籍を参照してください※）

# #### <練習問題 2-10>
# 
# $y = 5x + 3$ （$x$は$-10$から$10$の値）のグラフを描いてみましょう。

# #### <練習問題 2-11>
# 
# 「$y = sin(x)$」と「$y = cos(x)$」のグラフを重ねて描いてください（$x$は-10から10の値）

# #### <練習問題 2-12>
# 
# 0から1の値をとる一様乱数を1,000個、2組発生させて、それぞれのヒストグラムを描いてみましょう。
# 
# なお、それぞれのヒストグラムを別のグラフに表示するために、`plt.subplot`を利用してください。また、ここで一様乱数とは、ある数から別のある数まで等確率で発生する乱数のことをいい、`np.random.uniform`を使います。たとえば、0から1までの数を10個発生させる場合は、`np.random.uniform(0.0, 1.0, 10)`とします。
# 
# また、1,000個だけではなく、100個や10,000個などでも実施してみましょう。何かわかることはありますか。

# ## 2.6 総合問題

# ### ■総合問題2-1 モンテカルロ法
# 
# 乱数を発生させる方法を使って、円周率を求めるプログラムを作成してみましょう。なお、このアプローチを**モンテカルロ法**といいます。
# 
# （1）区間`[0,1]`上の一様分布に従う乱数を2組発生させて、それぞれ10,000個の一様乱数を作ってみましょう。
# なお、一様乱数とは、ある数から数まで等確率で発生する乱数のことです。`np.random.uniform`を使います。たとえば、`np.random.uniform(0.0, 1.0, 10)`とすると、0～1までの範囲の一様乱数を10個発生できます。
# 
# （2）$x−y$軸を使った中心$(0,0)$、半径1の円と、長さ1の正方形を考えます。このとき円の面積は$\pi$となり、正方形の面積は1となります。ここで先ほどの$x$と$y$の組み合わせの乱数10000個のうち、円の内部に入る点は何組あるでしょうか。
# 
# ここで、円の内部に入るとは、$x−y$座標の原点から点$ (x, y) $のベクトルの長さを求め、それが1より小さくなる場合を判定基準とします。その長さを求めるために、ユークリッドノルム($\sqrt{x^2 + y^2}$)を使います。Pythonでは、 `math.hypot(x,y)`で計算できます。さらに余裕があれば、円の中に入った$x$と$y$の組み合わせと外に出た$x$と$y$の組み合わせをプロットして図にしてみましょう。
# 
# 
# （3）半径1の1/4の円の面積と長さ1の正方形の面積の比は、$ \pi /4 : 1$となりますので、これと先ほどの結果を利用して、円周率を求めてみましょう。
